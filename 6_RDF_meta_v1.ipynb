{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import DCTERMS, RDF, RDFS, XSD, FOAF, DC\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# BASE URI\n",
    "BASE_URI = \"http://example.org/\"\n",
    "EX = Namespace(BASE_URI)\n",
    "WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "CC = Namespace(\"http://creativecommons.org/ns#\")\n",
    "WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "dc1 = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def init_graph():\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX)\n",
    "    g.bind(\"wd\", WD)\n",
    "    g.bind(\"wdt\", WDT)\n",
    "    g.bind(\"xsd\", XSD)\n",
    "    g.bind(\"cc\", CC)\n",
    "    g.bind(\"foaf\", FOAF)\n",
    "    g.bind(\"dc\", dc1)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blank_node(graph, subject):\n",
    "    # 使用 Blank Node 來生成匿名節點\n",
    "    blank_node = URIRef(f\"_:b{hash(subject)}\")\n",
    "    return blank_node\n",
    "\n",
    "def convert_article_to_rdf(graph, article_data):\n",
    "    file_id = article_data[\"filename\"].replace(\" \", \"_\")\n",
    "    article_uri = URIRef(EX[f\"doc/{file_id}\"])\n",
    "    \n",
    "    # 使用標準類型\n",
    "    graph.add((article_uri, RDF.type, FOAF.Document))\n",
    "\n",
    "    # 標題（使用 dc:title）\n",
    "    title = article_data.get(\"titles\", [])\n",
    "    if title:\n",
    "        graph.add((article_uri, DC.title, Literal(title[0])))\n",
    "\n",
    "    # 網址（使用 dc:source 或 dc:identifier）\n",
    "    url = article_data.get(\"URL\")\n",
    "    if url:\n",
    "        graph.add((article_uri, DC.identifier, URIRef(url)))\n",
    "\n",
    "    # 日期（dc:date）\n",
    "    raw_date = article_data.get(\"published_date\")\n",
    "    if raw_date:\n",
    "        for fmt in (\"%Y-%m-%d\", \"%Y/%m/%d\"):\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(raw_date, fmt)\n",
    "                graph.add((article_uri, DC.date, Literal(parsed_date.date().isoformat(), datatype=XSD.date)))\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"⚠️ 日期格式錯誤（跳過）: {raw_date} in {article_data['filename']}\")\n",
    "\n",
    "    # 作者（dc:creator）\n",
    "    author = article_data.get(\"author\")\n",
    "    if isinstance(author, str):\n",
    "        graph.add((article_uri, DC.creator, Literal(author)))\n",
    "    elif isinstance(author, list):\n",
    "        for a in author:\n",
    "            graph.add((article_uri, DC.creator, Literal(a)))\n",
    "\n",
    "    # Metadata 中的檔案資訊\n",
    "    metadata_raw = article_data.get(\"metadata\", [])\n",
    "    if isinstance(metadata_raw, dict):\n",
    "        metadata_list = [metadata_raw]\n",
    "    elif isinstance(metadata_raw, list):\n",
    "        metadata_list = [item for item in metadata_raw if isinstance(item, dict)]\n",
    "    else:\n",
    "        metadata_list = []\n",
    "\n",
    "    for metadata in metadata_list:\n",
    "        file_number = metadata.get(\"檔號\")\n",
    "        if not file_number:\n",
    "            continue\n",
    "\n",
    "        file_uri = generate_blank_node(graph, f\"file_{file_number}\")\n",
    "        graph.add((file_uri, RDF.type, EX.ArchiveFile))\n",
    "        graph.add((file_uri, WDT[\"P217\"], Literal(file_number)))\n",
    "\n",
    "        # 與文件關聯\n",
    "        graph.add((article_uri, EX.relatedFile, file_uri))\n",
    "\n",
    "        if \"案名\" in metadata:\n",
    "            graph.add((file_uri, DC.title, Literal(metadata[\"案名\"])))\n",
    "        if \"來源機關\" in metadata:\n",
    "            graph.add((file_uri, DC.creator, Literal(metadata[\"來源機關\"])))\n",
    "        if \"管有機關\" in metadata:\n",
    "            graph.add((file_uri, DC.publisher, Literal(metadata[\"管有機關\"])))\n",
    "        if \"檔案影像\" in metadata:\n",
    "            graph.add((file_uri, EX.imageNumber, Literal(metadata[\"檔案影像\"])))\n",
    "        \n",
    "        graph.add((article_uri, DCTERMS.rights, Literal(\"本資料依據創用 CC 姓名標示-非商業性 3.0 授權條款釋出\")))\n",
    "        graph.add((article_uri, URIRef(\"http://creativecommons.org/ns#license\"), URIRef(\"http://creativecommons.org/licenses/by-nc/3.0/\")))\n",
    "        graph.add((article_uri, URIRef(\"http://creativecommons.org/ns#attributionName\"), Literal(\"檔案管理局\")))\n",
    "        graph.add((article_uri, URIRef(\"http://creativecommons.org/ns#attributionURL\"), URIRef(\"https://www.archives.gov.tw\")))\n",
    "\n",
    "    # 處理其他補充欄位\n",
    "    other_fields = {\n",
    "        \"source\": DC.source,\n",
    "        \"license\": URIRef(\"http://creativecommons.org/licenses/by-nc/3.0/\"),\n",
    "        \"type\": EX.type,\n",
    "        \"theme\": EX.theme,\n",
    "        \"place\": EX.place,\n",
    "        \"time\": EX.time,\n",
    "    }\n",
    "\n",
    "    for field, predicate in other_fields.items():\n",
    "        value = article_data.get(field)\n",
    "        if value:\n",
    "            if isinstance(predicate, URIRef):\n",
    "                # 如果是 license URI，直接加入\n",
    "                graph.add((article_uri, DC.rights, predicate))\n",
    "            else:\n",
    "                if isinstance(value, list):\n",
    "                    for v in value:\n",
    "                        graph.add((article_uri, predicate, Literal(v)))\n",
    "                else:\n",
    "                    graph.add((article_uri, predicate, Literal(value)))\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 4. 主程式邏輯（選擇單檔或多檔輸出）\n",
    "\n",
    "\n",
    "def convert_json_to_rdf(json_path, output_dir=\"output\", one_file=True):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if one_file:\n",
    "        g = init_graph()\n",
    "        for article in data:\n",
    "            convert_article_to_rdf(g, article)\n",
    "        g.serialize(destination=output_dir / \"all_articles.ttl\", format=\"turtle\", base=BASE_URI)\n",
    "    else:\n",
    "        for article in data:\n",
    "            g = init_graph()\n",
    "            convert_article_to_rdf(g, article)\n",
    "            filename = article[\"filename\"].replace(\" \", \"_\")\n",
    "            g.serialize(destination=output_dir / f\"{filename}.ttl\", format=\"turtle\", base=BASE_URI)\n",
    "\n",
    "\n",
    "## 5. 批次讀取目錄中 JSON 檔案並提取欄位\n",
    "\n",
    "\n",
    "def extract_json_fields(json_dir):\n",
    "    results = []\n",
    "    for filename in os.listdir(json_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            path = os.path.join(json_dir, filename)\n",
    "            try:\n",
    "                with open(path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                result = {\n",
    "                    \"filename\": filename,\n",
    "                    \"titles\": data.get(\"titles\", []),\n",
    "                    \"author\": data.get(\"author\", []),  # 注意這裡是 'author' 且是列表\n",
    "                    \"published_date\": data.get(\"published_date\", \"\"),\n",
    "                    \"URL\": data.get(\"URL\", \"\"),\n",
    "                    \"metadata\": data.get(\"metadata\", [])\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"❌ JSON格式錯誤：{filename} — {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_json_fields(json_dir):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(json_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            path = os.path.join(json_dir, filename)\n",
    "            try:\n",
    "                with open(path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                result = {\n",
    "                    \"filename\": filename,\n",
    "                    \"titles\": data.get(\"titles\"),\n",
    "                    \"author\": data.get(\"author\"),\n",
    "                    \"published_date\": data.get(\"published_date\"),\n",
    "                    \"URL\": data.get(\"URL\"),\n",
    "                    \"metadata\": data.get(\"metadata\", [])\n",
    "                }\n",
    "                results.append(result)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"❌ JSON格式錯誤：{filename} — {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "## 6. 批次轉換整個資料夾內 JSON 為 RDF\n",
    "\n",
    "def convert_json_directory_to_rdf(json_dir, output_dir=\"output\", one_file=True):\n",
    "    articles = extract_json_fields(json_dir)\n",
    "\n",
    "    intermediate_file = Path(output_dir) / \"_temp_articles.json\"\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(intermediate_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(articles, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    convert_json_to_rdf(intermediate_file, output_dir=output_dir, one_file=one_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = \"./docs/output/2_metadata/done\"\n",
    "out_dir = \"./docs/output/6_rdf\"\n",
    "convert_json_directory_to_rdf(json_dir, out_dir, one_file=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 步驟 1: 載入 TTL 檔案 ===\n",
    "g = Graph()\n",
    "ttl_path = \"./docs/output/6_rdf/all_articles.ttl\"  # 👉 這裡請改成你的檔名，例如 \"data/228事件.ttl\"\n",
    "g.parse(ttl_path, format=\"turtle\")\n",
    "print(f\"Graph has {len(g)} triples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共有 8824 筆三元組\n",
      "不重複三元組數量：8824\n"
     ]
    }
   ],
   "source": [
    "# 取得唯一的三元組\n",
    "unique_triples = set(g)\n",
    "print(f\"總共有 {len(g)} 筆三元組\")\n",
    "print(f\"不重複三元組數量：{len(unique_triples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
